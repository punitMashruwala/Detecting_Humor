{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CPU\n",
      "\n",
      "\n",
      "\n",
      "# RAM\n",
      "\n",
      "# GPU\n",
      "\n",
      "# OS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from ast import literal_eval\n",
    "\n",
    "def run(command):\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    out, err = process.communicate()\n",
    "    print(out.decode('utf-8').strip())\n",
    "\n",
    "print('# CPU')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\n",
    "run('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')\n",
    "\n",
    "print('# RAM')\n",
    "run('cat /proc/meminfo | egrep \"^MemTotal\"')\n",
    "\n",
    "print('# GPU')\n",
    "run('lspci | grep VGA')\n",
    "\n",
    "print('# OS')\n",
    "run('uname -a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "# import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from transformers import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re    #for regex\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "MODEL_TYPE = 'bert-base-uncased'\n",
    "MAX_SIZE = 200\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read data and tokenizer\n",
    "\n",
    "Read tokenizer and data, as well as defining the maximum sequence length that will be used for the input to Bert (maximum is usually 512 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAS_ANS = False\n",
    "training_sample_count = 1000 # 4000\n",
    "training_epochs = 2 # 3\n",
    "test_count = 1000\n",
    "running_folds = 1 # 2\n",
    "MAX_SEQUENCE_LENGTH = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  is_humor\n",
      "0     TENNESSEE: We're the best state. Nobody even c...         1\n",
      "1     A man inserted an advertisement in the classif...         1\n",
      "2     How many men does it take to open a can of bee...         1\n",
      "3     Told my mom I hit 1200 Twitter followers. She ...         1\n",
      "4     Roses are dead. Love is fake. Weddings are bas...         1\n",
      "...                                                 ...       ...\n",
      "7995  Lack of awareness of the pervasiveness of raci...         0\n",
      "7996    Why are aspirins white? Because they work sorry         1\n",
      "7997  Today, we Americans celebrate our independence...         1\n",
      "7998  How to keep the flies off the bride at an Ital...         1\n",
      "7999  \"Each ounce of sunflower seeds gives you 37% o...         0\n",
      "\n",
      "[8000 rows x 2 columns]\n",
      "[\"TENNESSEE: We're the best state. Nobody even comes close. *Elevennessee walks into the room* TENNESSEE: Oh shit...\"\n",
      " 'A man inserted an advertisement in the classifieds \"Wife Wanted\". The next day, he received 1000 of replies, all reading: \"You can have mine.\" Free delivery also available at your door step'\n",
      " 'How many men does it take to open a can of beer? None. It should be open by the time she brings it to the couch.'\n",
      " ...\n",
      " 'Today, we Americans celebrate our independence from Britain while planning our escape to Canada.'\n",
      " 'How to keep the flies off the bride at an Italian wedding Keep a bucket of shit next to her'\n",
      " '\"Each ounce of sunflower seeds gives you 37% of your daily need for vitamin E\" vitamin health']\n",
      "[1 1 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df[['text','is_humor']]\n",
    "print(df)\n",
    "X = df.iloc[:, 0].values\n",
    "Y = df.iloc[:, 1].values\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset -> \n",
      "                                                text  is_humor\n",
      "0  TENNESSEE: We're the best state. Nobody even c...         1\n",
      "1  A man inserted an advertisement in the classif...         1\n",
      "2  How many men does it take to open a can of bee...         1\n",
      "3  Told my mom I hit 1200 Twitter followers. She ...         1\n",
      "4  Roses are dead. Love is fake. Weddings are bas...         1\n",
      " Test Dataset ->\n",
      "                                                text\n",
      "0  What's the difference between a Bernie Sanders...\n",
      "1     Vodka, whisky, tequila. I'm calling the shots.\n",
      "2     French people don't masturbate They Jacque off\n",
      "3  A lot of Suicide bombers are Muslims - I don't...\n",
      "4  What happens when you fingerbang a gypsy on he...\n",
      "Training entries: 8000, test entries: 1000\n"
     ]
    }
   ],
   "source": [
    "label_encoder_Y = LabelEncoder()\n",
    "Y = label_encoder_Y.fit_transform(Y)\n",
    "df_train = df\n",
    "df_test = pd.read_csv(\"public_dev.csv\")\n",
    "df_test = df_test[['text']]\n",
    "\n",
    "print(\"TRAIN Dataset -> \")\n",
    "print(df_train.head())\n",
    "print(\" Test Dataset ->\")\n",
    "print(df_test.head())\n",
    "\n",
    "df_test = df_test[:test_count]\n",
    "print(\"Training entries: {}, test entries: {}\".format(len(df_train), len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 8000 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_humor\n",
       "0  TENNESSEE: We're the best state. Nobody even c...         1\n",
       "1  A man inserted an advertisement in the classif...         1\n",
       "2  How many men does it take to open a can of bee...         1\n",
       "3  Told my mom I hit 1200 Twitter followers. She ...         1\n",
       "4  Roses are dead. Love is fake. Weddings are bas...         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the difference between a Bernie Sanders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vodka, whisky, tequila. I'm calling the shots.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French people don't masturbate They Jacque off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A lot of Suicide bombers are Muslims - I don't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What happens when you fingerbang a gypsy on he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  What's the difference between a Bernie Sanders...\n",
       "1     Vodka, whisky, tequila. I'm calling the shots.\n",
       "2     French people don't masturbate They Jacque off\n",
       "3  A lot of Suicide bombers are Muslims - I don't...\n",
       "4  What happens when you fingerbang a gypsy on he..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(df),len(df_train),len(df_test))\n",
    "display(df_train.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'is_humor']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input categories:\n",
      "\t ['text']\n",
      "\n",
      "output TARGET_COUNT:\n",
      "\t 1\n",
      "\n",
      "output categories:\n",
      "\t ['is_humor']\n"
     ]
    }
   ],
   "source": [
    "output_categories = list(df_train.columns[[1]])\n",
    "input_categories = list(df_train.columns[[0]])\n",
    "\n",
    "if HAS_ANS:\n",
    "    output_categories = list(df_train.columns[11:])\n",
    "    input_categories = list(df_train.columns[[1,2,5]])\n",
    "    \n",
    "\n",
    "TARGET_COUNT = len(output_categories)\n",
    "\n",
    "print('\\ninput categories:\\n\\t', input_categories)\n",
    "print('\\noutput TARGET_COUNT:\\n\\t', TARGET_COUNT)\n",
    "print('\\noutput categories:\\n\\t', output_categories)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing functions\n",
    "\n",
    "These are some functions that will be used to preprocess the raw text data into useable Bert inputs.<br>\n",
    "\n",
    "*update 4:* credits to [Minh](https://www.kaggle.com/dathudeptrai) for this implementation. If I'm not mistaken, it could be used directly with other Huggingface transformers too! Note that due to the 2 x 512 input, it will require significantly more memory when finetuning BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_to_transformer_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n",
    "    \n",
    "    def return_id(str1, str2, truncation_strategy, length):\n",
    "\n",
    "        inputs = tokenizer.encode_plus(str1, str2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=length,\n",
    "            truncation_strategy=truncation_strategy)\n",
    "        \n",
    "        input_ids =  inputs[\"input_ids\"]\n",
    "        input_masks = [1] * len(input_ids)\n",
    "        input_segments = inputs[\"token_type_ids\"]\n",
    "        padding_length = length - len(input_ids)\n",
    "        padding_id = tokenizer.pad_token_id\n",
    "        input_ids = input_ids + ([padding_id] * padding_length)\n",
    "        input_masks = input_masks + ([0] * padding_length)\n",
    "        input_segments = input_segments + ([0] * padding_length)\n",
    "        \n",
    "        return [input_ids, input_masks, input_segments]\n",
    "    \n",
    "    input_ids_q, input_masks_q, input_segments_q = return_id(\n",
    "        title, None, 'longest_first', max_sequence_length)\n",
    "    \n",
    "    input_ids_a, input_masks_a, input_segments_a = return_id(\n",
    "        '', None, 'longest_first', max_sequence_length)\n",
    "        \n",
    "    return [input_ids_q, input_masks_q, input_segments_q,\n",
    "            input_ids_a, input_masks_a, input_segments_a]\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n",
    "    input_ids_q, input_masks_q, input_segments_q = [], [], []\n",
    "    input_ids_a, input_masks_a, input_segments_a = [], [], []\n",
    "    for _, instance in tqdm(df[columns].iterrows()):\n",
    "        t, q, a = instance.text, instance.text, instance.text\n",
    "\n",
    "        ids_q, masks_q, segments_q, ids_a, masks_a, segments_a = \\\n",
    "        _convert_to_transformer_inputs(t, q, a, tokenizer, max_sequence_length)\n",
    "        \n",
    "        input_ids_q.append(ids_q)\n",
    "        input_masks_q.append(masks_q)\n",
    "        input_segments_q.append(segments_q)\n",
    "        input_ids_a.append(ids_a)\n",
    "        input_masks_a.append(masks_a)\n",
    "        input_segments_a.append(segments_a)\n",
    "        \n",
    "    return [np.asarray(input_ids_q, dtype=np.int32), \n",
    "            np.asarray(input_masks_q, dtype=np.int32), \n",
    "            np.asarray(input_segments_q, dtype=np.int32),\n",
    "            np.asarray(input_ids_a, dtype=np.int32), \n",
    "            np.asarray(input_masks_a, dtype=np.int32), \n",
    "            np.asarray(input_segments_a, dtype=np.int32)]\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d0e5395c9f402fbe2a779d020d2756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c8dccce7c14c9ea41508b25d07d32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = compute_output_arrays(df_train, output_categories)\n",
    "inputs = compute_input_arrays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create model\n",
    "\n",
    "~~`compute_spearmanr()`~~ `mean_squared_error` is used to compute the competition metric for the validation set\n",
    "<br><br>\n",
    "`create_model()` contains the actual architecture that will be used to finetune BERT to our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearmanr_ignore_nan(trues, preds):\n",
    "    rhos = []\n",
    "    for tcol, pcol in zip(np.transpose(trues), np.transpose(preds)):\n",
    "        rhos.append(spearmanr(tcol, pcol).correlation)\n",
    "    return np.nanmean(rhos)\n",
    "\n",
    "def create_model():\n",
    "    q_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    a_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    q_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    a_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    q_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    a_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
    "    \n",
    "    config = BertConfig() # print(config) to see settings\n",
    "    config.output_hidden_states = False # Set to True to obtain hidden states\n",
    "    # caution: when using e.g. XLNet, XLNetConfig() will automatically use xlnet-large config\n",
    "    \n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased', config=config)\n",
    "    \n",
    "    # if config.output_hidden_states = True, obtain hidden states via bert_model(...)[-1]\n",
    "    q_embedding = bert_model(q_id, attention_mask=q_mask, token_type_ids=q_atn)[0]\n",
    "    a_embedding = bert_model(a_id, attention_mask=a_mask, token_type_ids=a_atn)[0]\n",
    "    \n",
    "    q = tf.keras.layers.GlobalAveragePooling1D()(q_embedding)\n",
    "    a = tf.keras.layers.GlobalAveragePooling1D()(a_embedding)\n",
    "    \n",
    "#     x = tf.keras.layers.Concatenate()([q, q])\n",
    "    \n",
    "    x = tf.keras.layers.Dropout(0.2)(q)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(TARGET_COUNT, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[q_id, q_mask, q_atn, ], outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Obtain inputs and targets, as well as the indices of the train/validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_humor']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training, validation and testing\n",
    "\n",
    "Loops over the folds in gkf and trains each fold for 3 epochs --- with a learning rate of 3e-5 and batch_size of 6. A simple binary crossentropy is used as the objective-/loss-function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== \n",
      "mean_absolute_error  : 0.09999999999999999\n",
      "mean_squared_error  : 0.009999999999999998\n",
      "r2 score  : 0.96\n",
      "================== \n",
      "balanced_accuracy_score  : 0.5\n",
      "average_precision_score  : 0.5\n",
      "balanced_accuracy_score  : 0.5\n",
      "accuracy_score  : 0.5\n",
      "f1_score  : 0.6666666666666666\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "Acc 0.5 Prec 0.5 Rec 1.0 F1 0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation Metrics\n",
    "import sklearn\n",
    "def print_evaluation_metrics(y_true, y_pred, label='', is_regression=True, label2=''):\n",
    "    print('==================', label2)\n",
    "    ### For regression\n",
    "    if is_regression:\n",
    "        print('mean_absolute_error',label,':', sklearn.metrics.mean_absolute_error(y_true, y_pred))\n",
    "        print('mean_squared_error',label,':', sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "        print('r2 score',label,':', sklearn.metrics.r2_score(y_true, y_pred))\n",
    "        #     print('max_error',label,':', sklearn.metrics.max_error(y_true, y_pred))\n",
    "        return sklearn.metrics.mean_squared_error(y_true, y_pred)\n",
    "    else:\n",
    "        ### FOR Classification\n",
    "        print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
    "        print('average_precision_score',label,':', sklearn.metrics.average_precision_score(y_true, y_pred))\n",
    "        print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
    "        print('accuracy_score',label,':', sklearn.metrics.accuracy_score(y_true, y_pred))\n",
    "        print('f1_score',label,':', sklearn.metrics.f1_score(y_true, y_pred))\n",
    "        \n",
    "        matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "        print(matrix)\n",
    "        TP,TN,FP,FN = matrix[1][1],matrix[0][0],matrix[0][1],matrix[1][0]\n",
    "        Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "        Precision = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        F1 = 2*(Recall * Precision) / (Recall + Precision)\n",
    "        print('Acc', Accuracy, 'Prec', Precision, 'Rec', Recall, 'F1',F1)\n",
    "        return sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "print_evaluation_metrics([1,0], [0.9,0.1], '', True)\n",
    "print_evaluation_metrics([1,0], [1,1], '', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function selection\n",
    "Regression problem between 0 and 1, so binary_crossentropy and mean_absolute_error seem good.\n",
    "\n",
    "Here are the explanations: https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "LR= 1e-05\n",
      "(6, 1000, 300) (1000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "32/32 [==============================] - 1809s 57s/step - loss: 0.5794\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 1764s 55s/step - loss: 0.2468\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 1799s 56s/step - loss: 0.1068\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 1843s 58s/step - loss: 0.0420\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 1467s 46s/step - loss: 0.0116\n",
      "================== \n",
      "mean_absolute_error on #1 : 0.09396692630552934\n",
      "mean_squared_error on #1 : 0.0735357907604336\n",
      "r2 score on #1 : 0.6849682639069455\n",
      "new acc >>  0.0735357907604336\n",
      " \n"
     ]
    }
   ],
   "source": [
    "min_acc = 1000000\n",
    "min_test = []\n",
    "valid_preds = []\n",
    "test_preds = []\n",
    "best_model = False\n",
    "for LR in np.arange(1e-5, 2e-5, 3e-5).tolist():\n",
    "    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "    print('LR=', LR)\n",
    "    gkf = GroupKFold(n_splits=5).split(X=df_train.text, groups=df_train.text)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "        if fold not in range(running_folds):\n",
    "            continue\n",
    "        train_inputs = [(inputs[i][train_idx])[:training_sample_count] for i in range(len(inputs))]\n",
    "        train_outputs = (outputs[train_idx])[:training_sample_count]\n",
    "\n",
    "        valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n",
    "        valid_outputs = outputs[valid_idx]\n",
    "\n",
    "        print(np.array(train_inputs).shape, np.array(train_outputs).shape)\n",
    "#         print(train_idx[:10], valid_idx[:10])\n",
    "\n",
    "        K.clear_session()\n",
    "        model = create_model()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        for xx in range(1):\n",
    "            model.fit(train_inputs, train_outputs, epochs=training_epochs, batch_size=32, verbose=1)\n",
    "            # model.save_weights(f'bert-{fold}.h5')\n",
    "            valid_preds.append(model.predict(valid_inputs))\n",
    "            #rho_val = compute_spearmanr_ignore_nan(valid_outputs, valid_preds[-1])\n",
    "            #print('validation score = ', rho_val)\n",
    "            acc = print_evaluation_metrics(np.array(valid_outputs), np.array(valid_preds[-1]), 'on #'+str(xx+1))\n",
    "            if acc < min_acc:\n",
    "                print('new acc >> ', acc)\n",
    "                min_acc = acc\n",
    "                best_model = model\n",
    "#                 min_test = model.predict(test_inputs)\n",
    "#                 test_preds.append(min_test)\n",
    "            print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            769         dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,483,009\n",
      "Trainable params: 109,483,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best acc >>  0.0735357907604336\n"
     ]
    }
   ],
   "source": [
    "print('best acc >> ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1) (1600, 1)\n",
      "================== \n",
      "mean_absolute_error  : 0.09396692630552934\n",
      "mean_squared_error  : 0.0735357907604336\n",
      "r2 score  : 0.6849682639069455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0735357907604336"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(valid_outputs.shape, valid_preds[-1].shape)\n",
    "print_evaluation_metrics(np.array(valid_outputs), np.array(valid_preds[-1]), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "min_test = best_model.predict(test_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text      pred\n",
      "0    What's the difference between a Bernie Sanders...  0.999945\n",
      "1       Vodka, whisky, tequila. I'm calling the shots.  0.889932\n",
      "2       French people don't masturbate They Jacque off  0.999590\n",
      "3    A lot of Suicide bombers are Muslims - I don't...  0.999841\n",
      "4    What happens when you fingerbang a gypsy on he...  0.999941\n",
      "..                                                 ...       ...\n",
      "995  boss: what are you doing inventor of the bagpi...  0.999972\n",
      "996  I told him his views were pretty extreme and i...  0.014071\n",
      "997  \"Mum, all the black kids call each other Nigga...  0.999093\n",
      "998  In honor of Fathers Day, I'm gonna bring you \"...  0.001903\n",
      "999  I don't know why Coca-Cola and Pepsi are fight...  0.999948\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_sub = df_test.copy()\n",
    "# df_sub['pred'] = np.average(test_preds, axis=0) # for weighted average set weights=[...]\n",
    "df_sub['pred'] = min_test\n",
    "\n",
    "print(df_sub)\n",
    "# df_sub.to_csv('sub10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(min_test)):\n",
    "    min_test[i] = min_test[i] * 4\n",
    "df_sub['humor_rating'] = min_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>is_humor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the difference between a Bernie Sanders...</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>3.999778</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vodka, whisky, tequila. I'm calling the shots.</td>\n",
       "      <td>0.889932</td>\n",
       "      <td>3.559730</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French people don't masturbate They Jacque off</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>3.998360</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A lot of Suicide bombers are Muslims - I don't...</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>3.999364</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What happens when you fingerbang a gypsy on he...</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>3.999764</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      pred  humor_rating  \\\n",
       "0  What's the difference between a Bernie Sanders...  0.999945      3.999778   \n",
       "1     Vodka, whisky, tequila. I'm calling the shots.  0.889932      3.559730   \n",
       "2     French people don't masturbate They Jacque off  0.999590      3.998360   \n",
       "3  A lot of Suicide bombers are Muslims - I don't...  0.999841      3.999364   \n",
       "4  What happens when you fingerbang a gypsy on he...  0.999941      3.999764   \n",
       "\n",
       "   is_humor  \n",
       "0      True  \n",
       "1      True  \n",
       "2      True  \n",
       "3      True  \n",
       "4      True  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for split in np.arange(0.1, 0.80, 0.1).tolist():\n",
    "    df_sub['is_humor'] = (df_sub['pred'] > split)\n",
    "\n",
    "\n",
    "df_sub.to_csv('colbert_test.csv', index=False)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
